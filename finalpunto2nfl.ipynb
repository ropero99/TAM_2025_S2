{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:17:14.280055Z","iopub.execute_input":"2025-12-05T03:17:14.280255Z","iopub.status.idle":"2025-12-05T03:17:16.759504Z","shell.execute_reply.started":"2025-12-05T03:17:14.280237Z","shell.execute_reply":"2025-12-05T03:17:16.758478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install pytorch_tabnet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:17:16.761532Z","iopub.execute_input":"2025-12-05T03:17:16.762270Z","iopub.status.idle":"2025-12-05T03:18:38.308326Z","shell.execute_reply.started":"2025-12-05T03:17:16.762243Z","shell.execute_reply":"2025-12-05T03:18:38.307268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================\n# Rutas de datos \n# ============================\nDIRECTORIO_DATOS = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/train\"\nDIRECTORIO_TEST = \"/kaggle/input/nfl-big-data-bowl-2026-prediction\"\n\n\ndef cargar_entradas_y_salidas(directorio: str):\n    \"\"\"\n    Carga y concatena los CSV de entrada (pre-release) y salida (post-release)\n    para todas las semanas disponibles.\n\n    Returns\n    -------\n    datos_entrada : DataFrame\n        Todos los frames pre-release (10 Hz) de todos los jugadores\n        antes del lanzamiento del balón.\n    datos_salida : DataFrame\n        Frames post-release para los jugadores objetivo\n        (solo player_to_predict y durante el vuelo del balón).\n    \"\"\"\n    listas_entrada, listas_salida = [], []\n\n    for semana in range(1, 19):   # semanas 1 a 18\n        ruta_inp = os.path.join(directorio, f\"input_2023_w{semana:02d}.csv\")\n        ruta_out = os.path.join(directorio, f\"output_2023_w{semana:02d}.csv\")\n\n        if os.path.exists(ruta_inp):\n            listas_entrada.append(pd.read_csv(ruta_inp))\n\n        if os.path.exists(ruta_out):\n            listas_salida.append(pd.read_csv(ruta_out))\n\n    if not listas_entrada:\n        raise FileNotFoundError(\"No se encontraron archivos input_2023_wXX.csv en DIRECTORIO_DATOS.\")\n    if not listas_salida:\n        raise FileNotFoundError(\"No se encontraron archivos output_2023_wXX.csv en DIRECTORIO_DATOS.\")\n\n    datos_entrada = pd.concat(listas_entrada, ignore_index=True)\n    datos_salida = pd.concat(listas_salida, ignore_index=True)\n\n    return datos_entrada, datos_salida\n\n\ndef cargar_test_pre_release(directorio_test: str):\n    \"\"\"\n    Carga el archivo de test pre-release.\n    \"\"\"\n    ruta_test_input = os.path.join(directorio_test, \"test_input.csv\")\n    if not os.path.exists(ruta_test_input):\n        raise FileNotFoundError(\"No se encontró test_input.csv en DIRECTORIO_TEST.\")\n    return pd.read_csv(ruta_test_input)\n\n\n# ============================\n# Carga principal de datos\n# ============================\nentrada_, salida_ = cargar_entradas_y_salidas(DIRECTORIO_DATOS)\nentrada_test_ = cargar_test_pre_release(DIRECTORIO_TEST)\n\nprint(\"=== Estructura general de los DataFrames ===\")\nprint(f\"· Entrenamiento pre-release  : filas = {entrada_.shape[0]:,} | columnas = {entrada_.shape[1]}\")\nprint(f\"· Entrenamiento post-release : filas = {salida_.shape[0]:,} | columnas = {salida_.shape[1]}\")\nprint(f\"· Test pre-release           : filas = {entrada_test_.shape[0]:,} | columnas = {entrada_test_.shape[1]}\")\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:18:38.309495Z","iopub.execute_input":"2025-12-05T03:18:38.309786Z","iopub.status.idle":"2025-12-05T03:19:02.486588Z","shell.execute_reply.started":"2025-12-05T03:18:38.309757Z","shell.execute_reply":"2025-12-05T03:19:02.485671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"entrada_.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:19:02.487568Z","iopub.execute_input":"2025-12-05T03:19:02.488324Z","iopub.status.idle":"2025-12-05T03:19:02.519814Z","shell.execute_reply.started":"2025-12-05T03:19:02.488292Z","shell.execute_reply":"2025-12-05T03:19:02.519053Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"entrada_.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:19:02.520600Z","iopub.execute_input":"2025-12-05T03:19:02.521056Z","iopub.status.idle":"2025-12-05T03:19:02.572397Z","shell.execute_reply.started":"2025-12-05T03:19:02.521028Z","shell.execute_reply":"2025-12-05T03:19:02.571728Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocesamiento para dataset tabular base","metadata":{}},{"cell_type":"markdown","source":"## solo con los jugadores player_to_predict","metadata":{}},{"cell_type":"code","source":"# Nos quedamos solo con los jugadores objetivo\nentrada_players = entrada_.query(\"player_to_predict == True\").copy()\n\nprint(f\"jugadores objetivo = {entrada_players.shape}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:19:02.573204Z","iopub.execute_input":"2025-12-05T03:19:02.573456Z","iopub.status.idle":"2025-12-05T03:19:03.117973Z","shell.execute_reply.started":"2025-12-05T03:19:02.573435Z","shell.execute_reply":"2025-12-05T03:19:03.117152Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Elegir un frame de referencia por jugador\n\n* Tomamos, por defecto, el último frame pre-release para cada.\n* (game_id, play_id, nfl_id). Ese será el “snapshot” que ve TabNet.\n* Ahora entrada_ref tiene una fila por jugador a predecir.","metadata":{}},{"cell_type":"code","source":"id_cols = [\"game_id\", \"play_id\", \"nfl_id\"]\ncol_frame = \"frame_id\"   # en tu data ya se llama así\n\nentrada_ref = (\n    entrada_players\n      .sort_values(id_cols + [col_frame])\n      .groupby(id_cols, as_index=False)\n      .tail(1)          # último frame antes del release\n)\n\nprint(\"Frames de referencia:\", entrada_ref.shape)\nentrada_ref.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:19:03.120531Z","iopub.execute_input":"2025-12-05T03:19:03.121103Z","iopub.status.idle":"2025-12-05T03:19:03.566659Z","shell.execute_reply.started":"2025-12-05T03:19:03.121075Z","shell.execute_reply":"2025-12-05T03:19:03.565627Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## bloque multi-frame","metadata":{}},{"cell_type":"code","source":"# =====================================\n# 3. Construir targets multi-frame\n#    (x_t0, y_t0, x_t1, y_t1, ..., x_tK, y_tK)\n# =====================================\n\nid_cols = [\"game_id\", \"play_id\", \"nfl_id\"]\n\n# Determinar el número máximo de frames futuros según los datos reales\nT_MAX = int(entrada_players[\"num_frames_output\"].max())\nprint(\"T_MAX detectado (máx num_frames_output):\", T_MAX)\n\n# Ordenamos por IDs y frame, y creamos índice temporal t_idx\nsalida_sorted = salida_.sort_values(id_cols + [\"frame_id\"])\nsalida_sorted[\"t_idx\"] = salida_sorted.groupby(id_cols).cumcount()\n\n# Filtrar solo frames válidos [0 .. T_MAX-1]\nsalida_sorted = salida_sorted[salida_sorted[\"t_idx\"] < T_MAX].copy()\n\n# Pasamos de tabla \"larga\" a \"ancha\": columnas = x_tk, y_tk\ntargets_wide = salida_sorted.pivot_table(\n    index=id_cols,\n    columns=\"t_idx\",\n    values=[\"x\", \"y\"]\n)\n\n# Aplanar MultiIndex de columnas: ('x',0) -> 'x_t0'\ntargets_wide.columns = [\n    f\"{var}_t{t}\" for (var, t) in targets_wide.columns\n]\ntargets_wide = targets_wide.reset_index()\n\n# Lista de columnas de targets multi-frame\ntarget_cols = [c for c in targets_wide.columns if c.startswith(\"x_t\") or c.startswith(\"y_t\")]\n\nprint(\"targets_wide shape:\", targets_wide.shape)\nprint(\"Ejemplo de target_cols:\", target_cols[:10])\n\n# Rellenar posibles NaNs por fila (frames faltantes)\ntargets_wide[target_cols] = targets_wide[target_cols].fillna(method=\"ffill\", axis=1)\ntargets_wide[target_cols] = targets_wide[target_cols].fillna(method=\"bfill\", axis=1)\n\n# =====================================\n# 4. Merge final: features pre-release + targets multi-frame\n# =====================================\n\ndf_train_raw = entrada_ref.merge(\n    targets_wide,\n    on=id_cols,\n    how=\"inner\"\n)\n\nprint(\"df_train_raw multi-frame:\", df_train_raw.shape)\nprint(df_train_raw.columns[:25])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:19:03.567637Z","iopub.execute_input":"2025-12-05T03:19:03.567889Z","iopub.status.idle":"2025-12-05T03:19:04.487005Z","shell.execute_reply.started":"2025-12-05T03:19:03.567867Z","shell.execute_reply":"2025-12-05T03:19:04.486134Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Definir df_features y df_targets","metadata":{}},{"cell_type":"code","source":"# ============================\n# Definir X (features) e y (targets) para multi-frame\n# ============================\n\n# IDs que no entran como features\nid_cols = [\"game_id\", \"play_id\", \"nfl_id\"]\n\n# Columnas que NO usaremos como features\ncols_no_features = id_cols + target_cols + [\n    \"player_name\",\n    \"player_birth_date\",\n    \"player_height\",\n    \"player_to_predict\",\n]\n\ndf_features = df_train_raw.drop(columns=cols_no_features, errors=\"ignore\").copy()\ndf_targets  = df_train_raw[target_cols].copy()\n\nfeature_cols = df_features.columns.tolist()\n\nprint(\"Nº features:\", len(feature_cols))\nprint(\"Nº targets:\", len(target_cols))\nprint(\"Ejemplo feature_cols:\", feature_cols[:10])\nprint(\"Ejemplo target_cols:\", target_cols[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:19:04.488022Z","iopub.execute_input":"2025-12-05T03:19:04.488335Z","iopub.status.idle":"2025-12-05T03:19:04.529956Z","shell.execute_reply.started":"2025-12-05T03:19:04.488309Z","shell.execute_reply":"2025-12-05T03:19:04.529193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Marcar columnas categóricas y numéricas","metadata":{}},{"cell_type":"code","source":"# ============================\n# Categóricas vs Numéricas\n# ============================\n\n# categorias que si queremos usar \ncat_cols = [\n    \"play_direction\",\n    \"player_position\",\n    \"player_side\",\n    \"player_role\",\n]\n\n# Solo las que realmente están en df_features\ncat_cols = [c for c in cat_cols if c in feature_cols]\n\n# El resto → numéricas\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\nprint(\"Categóricas:\", cat_cols)\nprint(\"Numéricas  :\", num_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:19:04.530860Z","iopub.execute_input":"2025-12-05T03:19:04.531109Z","iopub.status.idle":"2025-12-05T03:19:04.536718Z","shell.execute_reply.started":"2025-12-05T03:19:04.531087Z","shell.execute_reply":"2025-12-05T03:19:04.535756Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Imputar NaNs","metadata":{}},{"cell_type":"code","source":"# ============================\n# Imputación de NaNs\n# ============================\n\n# Numéricas → mediana\nfor c in num_cols:\n    df_features[c] = df_features[c].astype(\"float32\")\n    df_features[c] = df_features[c].fillna(df_features[c].median())\n\n# Categóricas → 'Unknown'\nfor c in cat_cols:\n    df_features[c] = df_features[c].fillna(\"Unknown\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:19:04.537729Z","iopub.execute_input":"2025-12-05T03:19:04.538142Z","iopub.status.idle":"2025-12-05T03:19:04.582145Z","shell.execute_reply.started":"2025-12-05T03:19:04.538100Z","shell.execute_reply":"2025-12-05T03:19:04.581337Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Codificar categóricas + cat_idxs y cat_dims","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# ============================\n# LabelEncoding por columna categórica\n# ============================\n\nlabel_encoders = {}   # <-- NUEVO: guardamos los encoders para usarlos luego en test\n\nfor c in cat_cols:\n    le = LabelEncoder()\n    df_features[c] = le.fit_transform(df_features[c].astype(str))\n    label_encoders[c] = le   # <-- guardamos el encoder entrenado\n\n\n\n# ============================\n# cat_idxs y cat_dims según el orden de feature_cols\n# ============================\n\ncat_idxs = []\ncat_dims = []\n\nfor i, c in enumerate(feature_cols):\n    if c in cat_cols:\n        cat_idxs.append(i)\n        cat_dims.append(df_features[c].nunique())\n\nprint(\"cat_idxs:\", cat_idxs)\nprint(\"cat_dims:\", cat_dims)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:23:30.734626Z","iopub.execute_input":"2025-12-05T03:23:30.739190Z","iopub.status.idle":"2025-12-05T03:23:30.855112Z","shell.execute_reply.started":"2025-12-05T03:23:30.739041Z","shell.execute_reply":"2025-12-05T03:23:30.853796Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## X, y y split (ahora con y multi-frame)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np\n\n# ============================\n# Matrices finales\n# ============================\n\nX = df_features[feature_cols].values.astype(\"float32\")   # (N, 16)\ny = df_targets[target_cols].values.astype(\"float32\")     # (N, 50)\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nprint(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\nprint(\"X_valid:\", X_valid.shape, \"y_valid:\", y_valid.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:23:36.808824Z","iopub.execute_input":"2025-12-05T03:23:36.809139Z","iopub.status.idle":"2025-12-05T03:23:37.021401Z","shell.execute_reply.started":"2025-12-05T03:23:36.809117Z","shell.execute_reply":"2025-12-05T03:23:37.020513Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_targets[target_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:23:39.678219Z","iopub.execute_input":"2025-12-05T03:23:39.678582Z","iopub.status.idle":"2025-12-05T03:23:39.759440Z","shell.execute_reply.started":"2025-12-05T03:23:39.678554Z","shell.execute_reply":"2025-12-05T03:23:39.758437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features[feature_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:19:05.455884Z","iopub.execute_input":"2025-12-05T03:19:05.456168Z","iopub.status.idle":"2025-12-05T03:19:05.481875Z","shell.execute_reply.started":"2025-12-05T03:19:05.456140Z","shell.execute_reply":"2025-12-05T03:19:05.481083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:23:45.359948Z","iopub.execute_input":"2025-12-05T03:23:45.360307Z","iopub.status.idle":"2025-12-05T03:23:45.368176Z","shell.execute_reply.started":"2025-12-05T03:23:45.360280Z","shell.execute_reply":"2025-12-05T03:23:45.367011Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"print(\"Mínimo:\", entrada_players[\"num_frames_output\"].min())\nprint(\"Promedio:\", entrada_players[\"num_frames_output\"].mean())\nprint(\"Máximo:\", entrada_players[\"num_frames_output\"].max())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:43:54.531087Z","iopub.execute_input":"2025-12-05T03:43:54.531506Z","iopub.status.idle":"2025-12-05T03:43:54.543850Z","shell.execute_reply.started":"2025-12-05T03:43:54.531476Z","shell.execute_reply":"2025-12-05T03:43:54.542927Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Definir y entrenar TabNet (multi-output)","metadata":{}},{"cell_type":"code","source":"#!pip install pytorch-tabnet -q\n\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport torch\n\nreg = TabNetRegressor(\n    n_d=16,\n    n_a=16,\n    n_steps=4,\n    gamma=1.5,\n    n_independent=2,\n    n_shared=2,\n    lambda_sparse=1e-4,\n\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=1e-3),\n\n    mask_type=\"sparsemax\",\n    cat_idxs=cat_idxs,\n    cat_dims=cat_dims,\n    cat_emb_dim=2\n)\n\nreg.fit(\n    X_train, y_train,\n    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n    eval_name=[\"train\", \"valid\"],\n    eval_metric=[\"rmse\"],\n    max_epochs=200,\n    patience=30,\n    batch_size=1024,\n    virtual_batch_size=128,\n    num_workers=0,\n    drop_last=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:23:48.429875Z","iopub.execute_input":"2025-12-05T03:23:48.430205Z","iopub.status.idle":"2025-12-05T03:37:08.431780Z","shell.execute_reply.started":"2025-12-05T03:23:48.430180Z","shell.execute_reply":"2025-12-05T03:37:08.430560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================\n# SUBMISSION: predicción sobre test_input + test.csv\n# ============================\n\n# Cargamos test.csv (mock con la estructura real del test futuro)\nruta_test_csv = os.path.join(DIRECTORIO_TEST, \"test.csv\")\ntest_df = pd.read_csv(ruta_test_csv)\n\nid_cols = [\"game_id\", \"play_id\", \"nfl_id\"]\n\n# 1) Snapshot pre-release para test (igual que en train)\nentrada_test_players = entrada_test_.query(\"player_to_predict == True\").copy()\n\nentrada_test_ref = (\n    entrada_test_players\n      .sort_values(id_cols + [\"frame_id\"])\n      .groupby(id_cols, as_index=False)\n      .tail(1)   # último frame pre-release\n)\n\nprint(\"entrada_test_ref:\", entrada_test_ref.shape)\n\n# 2) Construir df_test_features con MISMAS columnas que en el train\ndf_test_features = entrada_test_ref[feature_cols].copy()\n\n# === Imputación en test: usamos medianas del train y 'Unknown' ===\nfor c in num_cols:\n    df_test_features[c] = df_test_features[c].astype(\"float32\")\n    df_test_features[c] = df_test_features[c].fillna(df_features[c].median())\n\nfor c in cat_cols:\n    df_test_features[c] = df_test_features[c].fillna(\"Unknown\")\n    # aplicar el mismo encoder del train\n    le = label_encoders[c]\n    # cuidado: categorías nuevas -> las mandamos a una categoría \"desconocida\"\n    df_test_features[c] = df_test_features[c].map(\n        lambda v: v if v in le.classes_ else le.classes_[0]\n    )\n    df_test_features[c] = le.transform(df_test_features[c].astype(str))\n\n# 3) Matriz X_test\nX_test = df_test_features[feature_cols].values.astype(\"float32\")\n\n# 4) Predicción multi-frame\ny_test_pred = reg.predict(X_test)  # shape = (N_jugadores_test, n_targets)\n\n# 5) Convertimos a DataFrame con mismos nombres de columnas que target_cols\npred_multi = pd.DataFrame(y_test_pred, columns=target_cols)\nfor c in id_cols:\n    pred_multi[c] = entrada_test_ref[c].values\n\n# 6) Expandir a formato largo: una fila por frame_id\nn_targets = len(target_cols)\nn_frames = n_targets // 2  # pares (x_tk, y_tk)\n\nrows = []\nfor _, row in pred_multi.iterrows():\n    gid, pid, nid = int(row[\"game_id\"]), int(row[\"play_id\"]), int(row[\"nfl_id\"])\n    for t in range(n_frames):\n        frame_id = t + 1  # t_idx 0 -> frame_id 1\n        x_val = row[f\"x_t{t}\"]\n        y_val = row[f\"y_t{t}\"]\n        rows.append({\n            \"game_id\": gid,\n            \"play_id\": pid,\n            \"nfl_id\":  nid,\n            \"frame_id\": frame_id,\n            \"x\": x_val,\n            \"y\": y_val\n        })\n\npred_long = pd.DataFrame(rows)\n\nprint(\"pred_long (toda la trayectoria):\", pred_long.shape)\n\n# 7) Nos quedamos solo con los frames que Kaggle realmente evalúa (test.csv)\nsubmission = test_df.merge(\n    pred_long,\n    on=[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"],\n    how=\"left\"\n)\n\n# 8) Guardar archivo final de envío\nsubmission = submission[[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\", \"x\", \"y\"]]\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"submission listo:\", submission.shape)\nsubmission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:40:49.584588Z","iopub.execute_input":"2025-12-05T03:40:49.585712Z","iopub.status.idle":"2025-12-05T03:40:50.132973Z","shell.execute_reply.started":"2025-12-05T03:40:49.585679Z","shell.execute_reply":"2025-12-05T03:40:50.132025Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Métricas multi-frame","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ny_pred_valid = reg.predict(X_valid)   # (N, 50)\n\n# RMSE global (todas las coordenadas de todos los frames)\nmse_global = mean_squared_error(\n    y_valid.reshape(-1),\n    y_pred_valid.reshape(-1)\n)\nrmse_global = np.sqrt(mse_global)\n\nprint(\"RMSE Global multi-frame:\", rmse_global)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:41:17.645517Z","iopub.execute_input":"2025-12-05T03:41:17.646352Z","iopub.status.idle":"2025-12-05T03:41:17.900837Z","shell.execute_reply.started":"2025-12-05T03:41:17.646318Z","shell.execute_reply":"2025-12-05T03:41:17.899764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport numpy as np\n\n# ============================\n# MÉTRICAS GLOBALES (todos los frames y coordenadas)\n# ============================\n\n# Aplanamos todo: (N, n_targets) -> (N * n_targets,)\ny_true_flat = y_valid.reshape(-1)\ny_pred_flat = y_pred_valid.reshape(-1)\n\n# MSE\nmse_global = mean_squared_error(y_true_flat, y_pred_flat)\n\n# RMSE\nrmse_global = np.sqrt(mse_global)\n\n# MAE\nmae_global = mean_absolute_error(y_true_flat, y_pred_flat)\n\n# MAPE (evitando división por cero)\nepsilon = 1e-7\nmape_global = np.mean(\n    np.abs((y_valid - y_pred_valid) / (y_valid + epsilon))\n) * 100\n\n# R²\nr2_global = r2_score(y_true_flat, y_pred_flat)\n\nprint(\"====== MÉTRICAS GLOBALES ======\")\nprint(f\"MSE Global : {mse_global:.4f}\")\nprint(f\"RMSE Global: {rmse_global:.4f}\")\nprint(f\"MAE Global : {mae_global:.4f}\")\nprint(f\"MAPE Global: {mape_global:.4f}%\")\nprint(f\"R² Global  : {r2_global:.4f}\")\n\n\n# ============================\n# (OPCIONAL) RMSE por frame\n# ============================\n\nn_targets = y_valid.shape[1]\nassert n_targets % 2 == 0, \"Se espera pares (x_t, y_t) por frame\"\n\nn_frames = n_targets // 2\n\nrmse_por_frame = []\n\nfor t in range(n_frames):\n    # índices de x_t, y_t en el vector de targets\n    idx_x = 2 * t\n    idx_y = 2 * t + 1\n    \n    y_true_xy = y_valid[:, [idx_x, idx_y]]\n    y_pred_xy = y_pred_valid[:, [idx_x, idx_y]]\n    \n    mse_t = mean_squared_error(\n        y_true_xy.reshape(-1),\n        y_pred_xy.reshape(-1)\n    )\n    rmse_t = np.sqrt(mse_t)\n    rmse_por_frame.append(rmse_t)\n\nprint(\"\\n====== RMSE POR FRAME (x_t, y_t juntos) ======\")\nfor t, rmse_t in enumerate(rmse_por_frame):\n    print(f\"Frame t={t}: RMSE = {rmse_t:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:41:21.862235Z","iopub.execute_input":"2025-12-05T03:41:21.862566Z","iopub.status.idle":"2025-12-05T03:41:21.954103Z","shell.execute_reply.started":"2025-12-05T03:41:21.862538Z","shell.execute_reply":"2025-12-05T03:41:21.953245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# ============================\n# Cálculo del RMSE oficial por frame\n# ============================\n\nrmse_oficial = []\n\nn_targets = y_valid.shape[1]\nn_frames = n_targets // 2\n\nfor t in range(n_frames):\n    idx_x = 2 * t\n    idx_y = 2 * t + 1\n\n    x_true = y_valid[:, idx_x]\n    y_true = y_valid[:, idx_y]\n    x_pred = y_pred_valid[:, idx_x]\n    y_pred = y_pred_valid[:, idx_y]\n\n    # Fórmula oficial\n    mse_t = ((x_true - x_pred)**2 + (y_true - y_pred)**2).mean() / 2\n    rmse_t = np.sqrt(mse_t)\n\n    rmse_oficial.append(rmse_t)\n\n# ============================\n# Gráfico\n# ============================\n\nplt.figure(figsize=(10,5))\nplt.plot(range(n_frames), rmse_oficial, marker='o', color='purple', linewidth=2)\nplt.xlabel(\"Frame futuro (t)\")\nplt.ylabel(\"RMSE oficial\")\nplt.title(\"RMSE oficial (métrica del concurso) por frame\")\nplt.grid(True, linestyle=\"--\", alpha=0.4)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:41:51.895640Z","iopub.execute_input":"2025-12-05T03:41:51.895984Z","iopub.status.idle":"2025-12-05T03:41:52.284366Z","shell.execute_reply.started":"2025-12-05T03:41:51.895959Z","shell.execute_reply":"2025-12-05T03:41:52.283521Z"}},"outputs":[],"execution_count":null}]}